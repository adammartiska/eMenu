{"ast":null,"code":"import { Source, isSource } from '../language/source.mjs';\nimport { TokenKind } from '../language/tokenKind.mjs';\nimport { Lexer, isPunctuatorTokenKind } from '../language/lexer.mjs';\nimport { printBlockString } from '../language/blockString.mjs';\n/**\n * Strips characters that are not significant to the validity or execution\n * of a GraphQL document:\n *   - UnicodeBOM\n *   - WhiteSpace\n *   - LineTerminator\n *   - Comment\n *   - Comma\n *   - BlockString indentation\n *\n * Note: It is required to have a delimiter character between neighboring\n * non-punctuator tokens and this function always uses single space as delimiter.\n *\n * It is guaranteed that both input and output documents if parsed would result\n * in the exact same AST except for nodes location.\n *\n * Warning: It is guaranteed that this function will always produce stable results.\n * However, it's not guaranteed that it will stay the same between different\n * releases due to bugfixes or changes in the GraphQL specification.\n *\n * Query example:\n *\n * ```graphql\n * query SomeQuery($foo: String!, $bar: String) {\n *   someField(foo: $foo, bar: $bar) {\n *     a\n *     b {\n *       c\n *       d\n *     }\n *   }\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * query SomeQuery($foo:String!$bar:String){someField(foo:$foo bar:$bar){a b{c d}}}\n * ```\n *\n * SDL example:\n *\n * ```graphql\n * \"\"\"\n * Type description\n * \"\"\"\n * type Foo {\n *   \"\"\"\n *   Field description\n *   \"\"\"\n *   bar: String\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * \"\"\"Type description\"\"\" type Foo{\"\"\"Field description\"\"\" bar:String}\n * ```\n */\n\nexport function stripIgnoredCharacters(source) {\n  const sourceObj = isSource(source) ? source : new Source(source);\n  const body = sourceObj.body;\n  const lexer = new Lexer(sourceObj);\n  let strippedBody = '';\n  let wasLastAddedTokenNonPunctuator = false;\n\n  while (lexer.advance().kind !== TokenKind.EOF) {\n    const currentToken = lexer.token;\n    const tokenKind = currentToken.kind;\n    /**\n     * Every two non-punctuator tokens should have space between them.\n     * Also prevent case of non-punctuator token following by spread resulting\n     * in invalid token (e.g. `1...` is invalid Float token).\n     */\n\n    const isNonPunctuator = !isPunctuatorTokenKind(currentToken.kind);\n\n    if (wasLastAddedTokenNonPunctuator) {\n      if (isNonPunctuator || currentToken.kind === TokenKind.SPREAD) {\n        strippedBody += ' ';\n      }\n    }\n\n    const tokenBody = body.slice(currentToken.start, currentToken.end);\n\n    if (tokenKind === TokenKind.BLOCK_STRING) {\n      strippedBody += printBlockString(currentToken.value, {\n        minimize: true\n      });\n    } else {\n      strippedBody += tokenBody;\n    }\n\n    wasLastAddedTokenNonPunctuator = isNonPunctuator;\n  }\n\n  return strippedBody;\n}","map":{"version":3,"sources":["/Users/adammartiska/Projects/eMenu/GUI/eMenu-customer/node_modules/graphql/utilities/stripIgnoredCharacters.mjs"],"names":["Source","isSource","TokenKind","Lexer","isPunctuatorTokenKind","printBlockString","stripIgnoredCharacters","source","sourceObj","body","lexer","strippedBody","wasLastAddedTokenNonPunctuator","advance","kind","EOF","currentToken","token","tokenKind","isNonPunctuator","SPREAD","tokenBody","slice","start","end","BLOCK_STRING","value","minimize"],"mappings":"AAAA,SAASA,MAAT,EAAiBC,QAAjB,QAAiC,wBAAjC;AACA,SAASC,SAAT,QAA0B,2BAA1B;AACA,SAASC,KAAT,EAAgBC,qBAAhB,QAA6C,uBAA7C;AACA,SAASC,gBAAT,QAAiC,6BAAjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,OAAO,SAASC,sBAAT,CAAgCC,MAAhC,EAAwC;AAC7C,QAAMC,SAAS,GAAGP,QAAQ,CAACM,MAAD,CAAR,GAAmBA,MAAnB,GAA4B,IAAIP,MAAJ,CAAWO,MAAX,CAA9C;AACA,QAAME,IAAI,GAAGD,SAAS,CAACC,IAAvB;AACA,QAAMC,KAAK,GAAG,IAAIP,KAAJ,CAAUK,SAAV,CAAd;AACA,MAAIG,YAAY,GAAG,EAAnB;AACA,MAAIC,8BAA8B,GAAG,KAArC;;AAEA,SAAOF,KAAK,CAACG,OAAN,GAAgBC,IAAhB,KAAyBZ,SAAS,CAACa,GAA1C,EAA+C;AAC7C,UAAMC,YAAY,GAAGN,KAAK,CAACO,KAA3B;AACA,UAAMC,SAAS,GAAGF,YAAY,CAACF,IAA/B;AACA;AACJ;AACA;AACA;AACA;;AAEI,UAAMK,eAAe,GAAG,CAACf,qBAAqB,CAACY,YAAY,CAACF,IAAd,CAA9C;;AAEA,QAAIF,8BAAJ,EAAoC;AAClC,UAAIO,eAAe,IAAIH,YAAY,CAACF,IAAb,KAAsBZ,SAAS,CAACkB,MAAvD,EAA+D;AAC7DT,QAAAA,YAAY,IAAI,GAAhB;AACD;AACF;;AAED,UAAMU,SAAS,GAAGZ,IAAI,CAACa,KAAL,CAAWN,YAAY,CAACO,KAAxB,EAA+BP,YAAY,CAACQ,GAA5C,CAAlB;;AAEA,QAAIN,SAAS,KAAKhB,SAAS,CAACuB,YAA5B,EAA0C;AACxCd,MAAAA,YAAY,IAAIN,gBAAgB,CAACW,YAAY,CAACU,KAAd,EAAqB;AACnDC,QAAAA,QAAQ,EAAE;AADyC,OAArB,CAAhC;AAGD,KAJD,MAIO;AACLhB,MAAAA,YAAY,IAAIU,SAAhB;AACD;;AAEDT,IAAAA,8BAA8B,GAAGO,eAAjC;AACD;;AAED,SAAOR,YAAP;AACD","sourcesContent":["import { Source, isSource } from '../language/source.mjs';\nimport { TokenKind } from '../language/tokenKind.mjs';\nimport { Lexer, isPunctuatorTokenKind } from '../language/lexer.mjs';\nimport { printBlockString } from '../language/blockString.mjs';\n/**\n * Strips characters that are not significant to the validity or execution\n * of a GraphQL document:\n *   - UnicodeBOM\n *   - WhiteSpace\n *   - LineTerminator\n *   - Comment\n *   - Comma\n *   - BlockString indentation\n *\n * Note: It is required to have a delimiter character between neighboring\n * non-punctuator tokens and this function always uses single space as delimiter.\n *\n * It is guaranteed that both input and output documents if parsed would result\n * in the exact same AST except for nodes location.\n *\n * Warning: It is guaranteed that this function will always produce stable results.\n * However, it's not guaranteed that it will stay the same between different\n * releases due to bugfixes or changes in the GraphQL specification.\n *\n * Query example:\n *\n * ```graphql\n * query SomeQuery($foo: String!, $bar: String) {\n *   someField(foo: $foo, bar: $bar) {\n *     a\n *     b {\n *       c\n *       d\n *     }\n *   }\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * query SomeQuery($foo:String!$bar:String){someField(foo:$foo bar:$bar){a b{c d}}}\n * ```\n *\n * SDL example:\n *\n * ```graphql\n * \"\"\"\n * Type description\n * \"\"\"\n * type Foo {\n *   \"\"\"\n *   Field description\n *   \"\"\"\n *   bar: String\n * }\n * ```\n *\n * Becomes:\n *\n * ```graphql\n * \"\"\"Type description\"\"\" type Foo{\"\"\"Field description\"\"\" bar:String}\n * ```\n */\n\nexport function stripIgnoredCharacters(source) {\n  const sourceObj = isSource(source) ? source : new Source(source);\n  const body = sourceObj.body;\n  const lexer = new Lexer(sourceObj);\n  let strippedBody = '';\n  let wasLastAddedTokenNonPunctuator = false;\n\n  while (lexer.advance().kind !== TokenKind.EOF) {\n    const currentToken = lexer.token;\n    const tokenKind = currentToken.kind;\n    /**\n     * Every two non-punctuator tokens should have space between them.\n     * Also prevent case of non-punctuator token following by spread resulting\n     * in invalid token (e.g. `1...` is invalid Float token).\n     */\n\n    const isNonPunctuator = !isPunctuatorTokenKind(currentToken.kind);\n\n    if (wasLastAddedTokenNonPunctuator) {\n      if (isNonPunctuator || currentToken.kind === TokenKind.SPREAD) {\n        strippedBody += ' ';\n      }\n    }\n\n    const tokenBody = body.slice(currentToken.start, currentToken.end);\n\n    if (tokenKind === TokenKind.BLOCK_STRING) {\n      strippedBody += printBlockString(currentToken.value, {\n        minimize: true,\n      });\n    } else {\n      strippedBody += tokenBody;\n    }\n\n    wasLastAddedTokenNonPunctuator = isNonPunctuator;\n  }\n\n  return strippedBody;\n}\n"]},"metadata":{},"sourceType":"module"}